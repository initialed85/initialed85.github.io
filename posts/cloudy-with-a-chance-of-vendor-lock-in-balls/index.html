<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cloudy with a chance of vendor lock-in balls | initialed85's misc tech stuff</title>
<meta name=keywords content><meta name=description content="I started writing this article before I changed jobs, which was basically 6 months ago (in May 2023).
I&rsquo;m gonna basically leave it as it was and just mark up the parts I got wrong / the parts that turned out differently as an exercise in I dunno, maybe forced humility / embarassment?
So, let&rsquo;s dive into the article I wrote before I started the new gig and then follow it up with the last 6 months of reality."><meta name=author content="Edward Beech"><link rel=canonical href=https://initialed85.cc/posts/cloudy-with-a-chance-of-vendor-lock-in-balls/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://initialed85.cc/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://initialed85.cc/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://initialed85.cc/favicon-32x32.png><link rel=apple-touch-icon href=https://initialed85.cc/apple-touch-icon.png><link rel=mask-icon href=https://initialed85.cc/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Cloudy with a chance of vendor lock-in balls"><meta property="og:description" content="I started writing this article before I changed jobs, which was basically 6 months ago (in May 2023).
I&rsquo;m gonna basically leave it as it was and just mark up the parts I got wrong / the parts that turned out differently as an exercise in I dunno, maybe forced humility / embarassment?
So, let&rsquo;s dive into the article I wrote before I started the new gig and then follow it up with the last 6 months of reality."><meta property="og:type" content="article"><meta property="og:url" content="https://initialed85.cc/posts/cloudy-with-a-chance-of-vendor-lock-in-balls/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-06T17:38:34+08:00"><meta property="article:modified_time" content="2023-05-06T17:38:34+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Cloudy with a chance of vendor lock-in balls"><meta name=twitter:description content="I started writing this article before I changed jobs, which was basically 6 months ago (in May 2023).
I&rsquo;m gonna basically leave it as it was and just mark up the parts I got wrong / the parts that turned out differently as an exercise in I dunno, maybe forced humility / embarassment?
So, let&rsquo;s dive into the article I wrote before I started the new gig and then follow it up with the last 6 months of reality."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://initialed85.cc/posts/"},{"@type":"ListItem","position":2,"name":"Cloudy with a chance of vendor lock-in balls","item":"https://initialed85.cc/posts/cloudy-with-a-chance-of-vendor-lock-in-balls/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Cloudy with a chance of vendor lock-in balls","name":"Cloudy with a chance of vendor lock-in balls","description":"I started writing this article before I changed jobs, which was basically 6 months ago (in May 2023).\nI\u0026rsquo;m gonna basically leave it as it was and just mark up the parts I got wrong / the parts that turned out differently as an exercise in I dunno, maybe forced humility / embarassment?\nSo, let\u0026rsquo;s dive into the article I wrote before I started the new gig and then follow it up with the last 6 months of reality.","keywords":[],"articleBody":"I started writing this article before I changed jobs, which was basically 6 months ago (in May 2023).\nI’m gonna basically leave it as it was and just mark up the parts I got wrong / the parts that turned out differently as an exercise in I dunno, maybe forced humility / embarassment?\nSo, let’s dive into the article I wrote before I started the new gig and then follow it up with the last 6 months of reality.\nThe article from May Sorry it’s been so long since my last post- I’ve done lots of interesting things since then, but I’ve been too busy to write.\nHere’s a quick rundown:\nStill haven’t made any more music EDIT: No longer true, I made one track but it was a pretty constipated experience Set up CD for most of my disparate home Kubernetes stuff using Argo CD Lost interest in the FTP Game Jam as an excuse to learn Rust Code Playable (deployed on my Kubernetes cluster) Refactored more of my RC stuff as an excuse to continue learning Rust (both native and embedded for ESP32) Code Got the folks at my (old) job excited about Platform Engineering Started a migration from Docker and bespoke tooling to Kubernetes (and, to be fair, a bespoke installer) Decided to quit my job (lol) In seriousness though, unrelated to any of the above, just time for a change If you’re desperate to know company / role details, check out my LinkedIn I’m pretty sure there’s a meme about driving a Kubernetes migration and then leaving the company, but it’s fine- I’m pretty confident it’s the right choice and there’s a smarter guy than me who’s been working with me on it.\nWe’ve pulled together some cool but regrettably closed source stuff to make it more tractable for the nature of our customers (50-odd air-gapped on-prem instances); things like:\nAn offline K3s installer that bundles a few useful bits Wireguard config and binaries to ensure Kubernetes control plane and data plane are easy to request firewall rules for (single UDP port between nodes) Docker image and Kubernetes manifest for a local private registry Support for RHEL7, RHEL8, RHEL9 and Ubuntu 16.04, 18.04, 20.04 and 22.04 Some fun handling varying glibc versions here All easily built using Docker An offline installer that bundles a new install / upgrade of our own software Go-based, makes use of the Helm library and Docker library Bundles all Docker images of our software plus the prescribed VictoriaMetrics monitoring stack Bundles all the manifests as Helm charts Executes / rolls back cleanly I think if we can get it out the door it’ll take the complexity away from shipping the software and keeping it running (and allow us to remove a bunch of bespoke tooling that does an average job of things Kubernetes does for free).\nAnyway, my post today is in the context of my new job (that I don’t start for another couple of weeks) and me refreshing myself on the my understanding of the stack they’re using in the context of the challenges they’re facing.\nThe state of play (as far as I can tell) Flutter frontend EDIT: I was wrong about this- it was React Native) Go backend AWS for infrastructure EDIT: This was correct but oh boy, in the worst way The CTO and I were talking about encore.dev leading up the interview so I built on their chatbot example to make a ChatGPT variant to get some hands-on experience with the framework.\nIt wasn’t bad, I might do a post about it later on; but basically from the discussion with the CTO I infer that they’re either using Encore or they’re doing serverless AWS without a framework and finding that a challenge.\nSo I guess they’re either using Encore or they’re at least using Go (I assume serverless) and the CTO is trying to figure out how to reduce toil- fortunately Go is a language I’m very comfortable with so I think I can help out there.\nEDIT: Sure not serverless\nWithout truly knowing the spectrum of challenges they’re facing, I’m planning to bring some of my experience with around a robust software development lifecycle to the table and drive adoption from the front (by doing):\nKeep the whole team abreast of the context around what we’re focused on right now I think we’ve managed to achieve this Keep tickets small with clean acceptance criteria (and functional test cases if possible) Make good use of a code repo Monorepo can be a nice way to avoid dependency hell EDIT: We got to this, but I didn’t do it alone; much thanks to a guy called Luke Gelmi who came in keen and excited and drove this to victory Have an effective pull request process Aim for small / focused PRs Aim for a quick turnaround on PRs Try to balance feedback between “objectively bad” vs “just not my style” (don’t squash creativity) EDIT: I think we managed to hit all these Make it easy to spin up prod-like environments for development and testing EDIT: Definitely did this and I think it was our biggest gain Make it easy to execute a suite of tests against a prod-like environment EDIT: More or less achieved this Have a suite of tests and execute them at sensible times When we commit changes to a PR When we merge a PR Every night (because external dependencies sometimes break!) EDIT: Got all this with compromises; orchestrating a test environment was hard, so unit / integration tests run on commit, end-to-end tests are run locally (manually) and nightly against the deployed dev / staging environments Store artifacts against commit hashes We might have to roll back and maybe that version doesn’t build any more (but we know it works) EDIT: We did this Store all prod-related configuration in a code repo EDIT: We did this too Drive prod-related deployments from that code repo EDIT: Yep Have the right observability for what we’re doing Are we busy enough to rely on metrics? Is our logging good enough to drill into problem areas? Are our individual transactions important enough that we need to care about tracing? EDIT: Well we’ve got Grafana and we’ve got some metrics but it didn’t go much deeper than that- structured logging / tracing is still a TODO (but this represents sensible prioritisation) All of the above is underpinned by some good rules of thumb:\nDependencies should be version-pinned There will be enough problems simply with external package repo availability EDIT: This was pretty much already in-hand thanks to package.json and go.mod Important dependencies should be vendored Remember when everyone started yanking their Python 2 packages from PyPI? Remember when Debian deprecated the Slim dpkg repo? EDIT: This was prior experience that hasn’t been relevant as it turned out Artifact we deploy should be stored and versioned Makes it easy to redeploy it elsewhere, pick it apart for forensics etc EDIT: This was valuable and we did it Deployments should be immutable If we need to roll back, we should be able to do so by deploying a previous version EDIT: Same Deployments should be automated or close to automated It should be easy to execute a deployment, ideally easy enough that something else does it on our behalf EDIT: This has been hugely valuable Post-mortems we do should be truly blameless Individuals haven’t failed, our processes have EDIT: We haven’t been rigid at post-mortems; I’ve driven blameless as hard as I can, we’re just not very structured in post-mortems Automation helps a great deal with this:\nAutomated testing of components when their code changes e.g. unit tests / integration tests EDIT: Our coverage is definitely better here Automated storing of component artifacts when their tests pass e.g. Docker images / binaries EDIT: Well, we don’t push binaries if the preceding tests don’t pass Automated deployment of environments based on the state of a configuration management repo e.g. CDK / Terraform EDIT: Yep, thx Argo Automated testing of an environment when it’s deployed e.g. end-to-end tests / system tests EDIT: Well, sort of- we’ve got the nightlies This all sounds very imperative and prescriptive but I’m a pragmatic guy and we’ll apply these things in a way that works for us- ultimately we’re trying to reduce toil and increase velocity but along the way there’ll for sure be some critical items that need muscling a certain way to meet milestones and naturally those items will be prioritised above all else.\nI guess let’s say the above is a strategy but ultimately the needs of the business will dictate the tactics.\nExcitement or anxiety? I’m pretty comfortable with the soft-skills side of team leadership and I back myself technically, but I’m not strong with cloud so I wanted to try to get a feel for things before going in.\nEDIT: Predictably, more challenges than I had catered for, but I guess I had sort of catered for there being more challenges than I had catered for so it worked out okay\nProbably to a point of fault, I don’t like to plan and theorise too much before I start experimenting so I decided to slap together a demo repo to test out some concepts.\nEDIT: This spike was largely a waste of time, we landed with Pulumi and Argo\nIt’s not complete yet, I wanna try to cover off on the common serverless concepts but so far I’ve really only got the following:\nA minimal Go backend that so far just responds with some context about the request A minimal React frontend that is presently nothing beyond Create React App Some CDK to deploy the above with the following concepts: Lambda for the backend S3 for the frontend ALB in front of the Lambda CloudFront in front of it all A resource group to track it all I’ve tried to take my own medicine re: strategy above with a GitHub Action that does the following:\nTest all components as a gating mechanism Build all the component artifacts Ensure a “dependencies” infrastructure stack is deployed Basically just an S3 bucket for artifacts Deploy the component artifacts to the artifacts bucket Deploy the intended environment (e.g. dev, staging, prod) infrastructure stack Referring to the artifacts in the artifacts bucket Right now the building of the artifacts and the deploying of the artifacts are artificially coupled because there is no configuration management repo to drive the deployment of the infrastructure stack; decoupling them should be easy though because the artifacts are “versioned” in the artifacts bucket so it would be trivial to tell the infrastructure stack which version to use.\nThe reality between May and December-ish So, we’re back in realtime now- I’m not sure where to start; I guess lets go through some categorised dot-points…\nClint Eastwood The team was excited and keen for some leadership The app + platform was (just) launched and mostly working (especially given the fairly complicated task it had) There were 3 cloud environments (dev, staging, prod) Commits to the master branch of each repo would cause (except for the mobile app) the build and deployment of the component in question Lee Van Cleef Each dev’s local environment / local database was entirely self-managed So the completeness / correctness of your environment depends essentially on how skilled you are and how helpful the dev next to you is Everyone was developing on Windows No unit tests and no end-to-end tests (maybe one or two narrow-ish integration tests, but, to be fair, for some complicated parts of the system) A bunch of the senior devs (responsible for laying all the foundations) had got burnt out and left Two of them remained with about 2 / 3 weeks left when I arrived The breadth of the features of the system was (is) way too big for the problem domain As a result the system was large for how young it was, but nothing worked properly (due to the small team sprinting to kick something out the door but being swamped with too much functionality for an MVP) Eli Wallach Levels of abstraction were low (and levels of repetition were high) I don’t know for sure, but I think this is a byproduct of folks not having confidence in their code changes (no tests) and probably a decent amount of ChatGPT It doesn’t seem that the architecture side of the software was thought about a lot and it doesn’t look like code quality was pushed much in code reviews External interfaces would be a mixture of CamelCase and snake_case with no real pattern Pointers would be used far too much (when not required) causing numerous nil pointer panics where they could have been entirely avoided The flow of data through the system / the way it affected the state of the model was all over the shop Some poll-based, some event-based, no thought given to concurrency problems / locking The “DevOps” capability was a part-time resource in another country, on a different timezone Very little work-in at all with the dev team (some of them didn’t know he existed); basically the opposite of DevOps! The 3 cloud environments were similar but not the same on account of being built entirely by hand Absolutely no IaC to speak of Absolutely no backups of all the hand-crafted snowflake resources The deployment mechanism for the backend was worrying- a Bitbucket pipeline would use the default image (gasp) to build a Go binary for an unknown glibc version and literally SSH it through the front door of the backend EC2 VM where it was run entirely natively There’s a lot to unpack here The glibc thing bit us when Bitbucket arbitarily updated (as you’d expect) the Go version bundled in their CI image (resulting in a Go binary that wasn’t compatible with the glibc available on the EC2 VM) The EC2 VM had to be open to the world to permit Bitbucket to SSH artifacts in There was no rollback mechanism; the proven, running artifact was ripped out of existence and thrown in the bin then the new one was started- if the new one didn’t work, you’d have to start typing real fast The deployment mechanism for the frontend was even more worrying- a Bitbucket pipeline would literally SSH the code over to the frontend EC2 VM and then build it all there (somebody had already manually installed all the dependencies) We had dared to completely hand-roll Certbot stuff to handle LetsEnrypt cert changeovers Cron and slapped-together Bash- an accident just waiting to happen (and this is coming from a big fan of Bash) The approach since then I was immediately thrown into deep water (fair I guess, I had come on as the lead dev) and whether to sound me out or whether through necessity, the CTO had me wading through logs to get to the bottom of some prod issue within 2 days of getting there.\nFortunately Ops is my middle name and I’m familiar with AWS so finding the logs and the subsequent problem wasn’t too hard- it ended up being a silly and obvious nil pointer panic (one of the numerous that would plague us for a few months until we installed a handle-level panic recovery mechanism).\nRepeatability I was paralyzed for a week or two to be honest, just absolutely swamped in the sheer number of problems- when everything seems to be in a critical state, it becomes hard to work out where the right place to start chewing is.\nWe worked for a bit to get things halfway stable and get some grasp on what the team had promised to do in the near term and build a plan for doing that and then the obvious path started emerging.\nWe needed repeatable environments; these would stop us falling over ourselves, spending 2 days down the rabbithole chasing bugs that turned out to be stray stale data in local snowflake databases etc.\nThis was no mean feat and frankly it took months, but we had something workable fairly early; here’s where it landed:\nGet everyone off of Windows and onto Linux We had started off getting the devs out of native Windows dev and into WSL2 but it almost introduced more problems than it solved Moving to Ubuntu (batteries included) was well received and we saw a lot of benefit simply by writing code on the same platform we shipped code Devenv to handle the native dependencies (Go, Node, Android emulator, all sorts) and reduce the effort required to spin up a new dev (and reduce the odd issues introduced because e.g. Joe Bloggs has Node 16 and Jane Bloggs has Node 18) Docker Compose to orchestrate dependencies like Postgres, Stripe Webhook Forwarder etc as well as the actual services We weren’t yet running containers in prod, but I had a pretty good idea that this was where we were headed so getting containers in dev was a good way to get everyone exposed Overmind to orchestrate native dependencies This was a necessity to help devs move fast with full-stack changes (enabling hot reloads etc) It did introduce a lot of complexity however (because full hot reloading meant running natively which means we lost the containerisation benefits) So we ended up with a thing we call “the dev-env” (which is actually a name stolen from my last workplace and I daresay they weren’t the first place to describe such a concept) and two modes to operate it in (fully containerised or partially containerised with services running natively with hot reloading).\nIt’s been a big win- a developer comes in, spins up their dev-env which restores and migrates fresh databases, creates some fresh users (automated, but in the same way a user would signup, so free testing there), provisions some of the domain concepts that the system operates around and leaves them with some instructions on how to open the various services in their browser / emulator / mobile phone.\nAutomated testing Now that we had repeatable environments, the next thing we needed was some level of confidence that the system worked as expected- we had behaviour spread between the mobile app, the NextJS web app and the Go backend so I opted for Python as an easy way to pull together some end-to-end tests.\nI started out with a naive approach of just trying to cover every endpoint but some of the valuable interactions were spread across multiple endpoints and more than once service.\nSo, having already built out Python clients for every service (including Stripe) I basically built out some test cases that covered the most valuable user interactions and extended to a few common edge cases near them.\nJust doing this exercise found heaps of stuff (and heaps of inconsistencies, essentially race conditions) and now the same tests (which have grown a lot) are a valuable part of any release (and the nightly test runs).\nUnfortunately, I still haven’t been able to get entirely automated (e.g. on-commit) tests running in terms of entirely spinning up a clean and isolated dev-env and then executing tests against it mainly for the following reasons:\nThe full dev-env is heavy Bitbucket is super constrained in the subset of Docker capability it gives you So, a full clean end-to-end test run needs to be run on a dev’s workstation and the nightly runs happen against the already-deployed environments.\nMaybe I’ll spin up Jenkins or TeamCity or something like that, but its basically got to the point where we’re getting 90% of the value and that last 10% will take (has taken already) too much time for not that much value.\nBetter deployments It’s no secret that I love Kubernetes but I promise I’m not just a fanboi, truly I think it is great software- having wrangled as much Ops stuff as I have and been one of the key players in building out bespoke deployment tooling, you can see that the folks who built Kubernetes happened upon the same journey we did and came up with answers for all of it.\nThings like being able to describe the desired state of your system as code, being able to diff the current vs desired state and have the system achieve it for you, automating the toil around rolling out new versions of services, rolling back on failure, doing something useful with Docker healthchecks (startup / liveness probes etc)- I really do think it represents the peak of generic tech for shipping things as containers.\nSo naturally, that’s where we went- I got everything bundled into containers, I got it all building and pushing to AWS ECR on commit and I deployed an AWS EKS cluster (using Pulumi for the base IaC and Argo for the “app” IaC) to ship it all on.\nAnd I have to say, it has not missed a single beat and we simply do not worry about deployments any more; but here’s the best (and if you subscribe to the anti-hype, unexpected) part:\nIt’s cheaper to run.\nWell, cheaper to run than what we had before- we used to have about 12 (small to medium) EC2 VMs spanning the 3 environments and assorted services and understandably because hand-wrangling Nginx is difficult if you wanna stack all your services on a single VM.\nNow we’ve got 5 (smaller) nodes (probably only need 4) for all 3 environments and a stack of ancillary services as well as monitoring and I don’t need to worry about patching or anything.\nSo since I started, we’ve grown our service footprint a reasonable amount but somehow halved our monthly cloud spend and saved who knows how much developer time in putting fixes on top of fixes for bespoke deployment tooling (and dealing with the outages that come with that).\nMonorepo One of the first things I did when I started this new gig was set up about setting up a monorepo- but frankly I didn’t get very far, I got too caught up with trying to maintain throughput on features and releases while trying to improve our Way of Working.\n3 months in, all I really had to show for in the monorepo was the dev-env, the end-to-end tests and some of the ancillary services that we grew after I started.\nLuckily for me, we happened to hire an absolutely jet frontend dev a couple of months ago and he too believed in the value of a monorepo but unlike me, he wasn’t bogged down keeping the team ticking and keeping the lights on, so with very little guidance he was able to keep building out the rest of the monorepo to help us realise the dream.\nHe put in the hard yards getting the frontend code moved over and getting the dev-env working from the entirely new paths, leaving me with a bit of work to do in terms of getting all the Docker images building again and wiring in all the deployment pipelines and it was all done and dusted in about a month.\nThe win has been huge, devs have gone from opening 3 PRs for a single piece of work down to just 1 PR, any breaking changes can be looked at entirely in the context of the other changes for the same release, devs aren’t losing hours only to find the issue is because they were working on the frontend and had forgot to pull the latest backend etc.\nInteresting findings I can operate for about 2 weeks going to bed at 3am before my body takes over and demands sleep No guarantees about what sort of a person I am to be around as I near the 2 week mark I can migrate a prod environment from EC2 to Kubernetes in the quiet period between the service going quiet-ish ( midnight) and before business picks up again (5am-ish) with minimal downtime (mostly just the no-mans land while DNS is in an uncertain state) I don’t need anywhere near as much test coverage as I thought I did (coming from a large Python codebase)- I think this is because of the strongly-typed nature of Go Once this dawned on me, I became a lot less stressed, because I realised we weren’t in quite the bad shape I thought we were End-to-end test coverage is still important though, because complex behavioural / business domain-level bugs aren’t notably affected by things like strong typing in my experience I need to keep re-learning patterns about myself I’ll start out with a bit of “let’s just hack this thing in” mindset and it always, always grows into “okay this is more complex than I thought, time to write some tests” (I should really just start with the tests) The initially very daunting feeling of a large and foreign codebase and my natural inclination to hack and slash continue to take a while to equalize It’s really hard to tell (without somebody to ask) what parts of the code are important vs not important, proven and reliable vs flaky etc but until you know, you’ve really gotta treat lightly I’m always saying this, but I still, STILL don’t live it enough Other items of note We’re building out a new service that I can’t really speak a lot about at present, but it’s gonna allow us to cut out a bunch in current software licensing and it’s been super exciting to work on.\nI’ve been working closely with a somewhat junior Go dev that started the same day I did and it’s been really great to see him grow as a pragmatic Go developer by working on this new service (that doesn’t fit the typical mould of \" web-based backend\" and is more about complex interactions with devices deployed in the field).\nI’ve been able to share some wisdom and guide the approach (and I’ve had to compromise on some items- I swear buddy we’re gonna need that FSM and the complexity will be worth it but hey, you win for now) and I’m proud of the shape its taken.\nIn closing I’ll probably park the article here, it’s taken 6 months to write and its an almighty wall of text. All in all, I’m enjoying the new job and while it’s definitely a paycut (being a startup), the open / unsolved nature of the problem space and the (initially overwhelming) amount of opportunity to deliver some value has been super rewarding.\n","wordCount":"4408","inLanguage":"en","datePublished":"2023-05-06T17:38:34+08:00","dateModified":"2023-05-06T17:38:34+08:00","author":{"@type":"Person","name":"Edward Beech"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://initialed85.cc/posts/cloudy-with-a-chance-of-vendor-lock-in-balls/"},"publisher":{"@type":"Organization","name":"initialed85's misc tech stuff","logo":{"@type":"ImageObject","url":"https://initialed85.cc/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://initialed85.cc/ accesskey=h title="initialed85's misc tech stuff (Alt + H)">initialed85's misc tech stuff</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Cloudy with a chance of vendor lock-in balls</h1><div class=post-meta>&lt;span title='2023-05-06 17:38:34 +0800 +0800'>May 6, 2023&lt;/span>&amp;nbsp;·&amp;nbsp;21 min&amp;nbsp;·&amp;nbsp;Edward Beech</div></header><div class=post-content><p>I started writing this article before I changed jobs, which was basically 6 months ago (in May 2023).</p><p>I&rsquo;m gonna basically leave it as it was and just mark up the parts I got wrong / the parts that turned out differently as
an exercise in I dunno, maybe forced humility / embarassment?</p><p>So, let&rsquo;s dive into the article I wrote before I started the new gig and then follow it up with the last 6 months of
reality.</p><h2 id=the-article-from-may>The article from May<a hidden class=anchor aria-hidden=true href=#the-article-from-may>#</a></h2><p><img loading=lazy src=/posts/cloudy-with-a-chance-of-vendor-lock-in-balls/image-1.png alt=image-1.png></p><p>Sorry it&rsquo;s been so long since my last post- I&rsquo;ve done lots of interesting things since then, but I&rsquo;ve been too busy to
write.</p><p>Here&rsquo;s a quick rundown:</p><ul><li>Still haven&rsquo;t made any more <a href=https://soundcloud.com/initialed85>music</a><ul><li><em>EDIT: No longer true, I made one track but it
was <a href=https://soundcloud.com/initialed85/it-has-been-too-long>a pretty constipated experience</a></em></li></ul></li><li>Set up CD for most of my disparate home Kubernetes stuff using <a href=https://argoproj.github.io/cd/>Argo CD</a></li><li>Lost interest in the <a href=https://itch.io/jam/ftp-gamejam>FTP Game Jam</a> as an excuse to learn Rust<ul><li><a href=https://github.com/initialed85/eds-game-for-ftp-game-jam-2022>Code</a></li><li><a href=https://eds-game-for-ftp-game-jam-2022.initialed85.cc/>Playable</a> (deployed on my Kubernetes cluster)</li></ul></li><li>Refactored more of my RC stuff as an excuse to continue learning Rust (both native and embedded for ESP32)<ul><li><a href=https://github.com/initialed85/rc-things>Code</a></li></ul></li><li>Got the folks at my (old) job excited about Platform Engineering</li><li>Started a migration from Docker and bespoke tooling to Kubernetes (<em>and, to be fair, a bespoke installer</em>)</li><li>Decided to quit my job (lol)<ul><li>In seriousness though, unrelated to any of the above, just time for a change</li><li>If you&rsquo;re desperate to know company / role details, check
out <a href=https://www.linkedin.com/in/edward-beech-48442a74/>my LinkedIn</a></li></ul></li></ul><p>I&rsquo;m pretty sure there&rsquo;s a meme about driving a Kubernetes migration and then leaving the company, but it&rsquo;s fine- I&rsquo;m
pretty confident it&rsquo;s the right choice and there&rsquo;s a smarter guy than me who&rsquo;s been working with me on it.</p><p>We&rsquo;ve pulled together some cool but regrettably closed source stuff to make it more tractable for the nature of our
customers (50-odd air-gapped on-prem instances); things like:</p><ul><li>An offline <a href=https://k3s.io/>K3s</a> installer that bundles a few useful bits<ul><li>Wireguard config and binaries to ensure Kubernetes control plane and data plane are easy to request firewall rules
for (single UDP port between nodes)</li><li>Docker image and Kubernetes manifest for a local private registry</li><li>Support for RHEL7, RHEL8, RHEL9 and Ubuntu 16.04, 18.04, 20.04 and 22.04<ul><li>Some fun handling varying <code>glibc</code> versions here</li></ul></li><li>All easily built using Docker</li></ul></li><li>An offline installer that bundles a new install / upgrade of our own software<ul><li>Go-based, makes use of the Helm library and Docker library</li><li>Bundles all Docker images of our software plus the prescribed VictoriaMetrics monitoring stack</li><li>Bundles all the manifests as Helm charts</li><li>Executes / rolls back cleanly</li></ul></li></ul><p>I think if we can get it out the door it&rsquo;ll take the complexity away from shipping the software and keeping it running
(and allow us to remove a bunch of bespoke tooling that does an average job of things Kubernetes does for free).</p><p>Anyway, my post today is in the context of my new job (that I don&rsquo;t start for another couple of weeks) and me refreshing
myself on the my understanding of the stack they&rsquo;re using in the context of the challenges they&rsquo;re facing.</p><h3 id=the-state-of-play-as-far-as-i-can-tell>The state of play (as far as I can tell)<a hidden class=anchor aria-hidden=true href=#the-state-of-play-as-far-as-i-can-tell>#</a></h3><ul><li><a href=https://flutter.dev/>Flutter</a> frontend<ul><li><em>EDIT: I was wrong about this- it was React Native)</em></li></ul></li><li><a href=https://go.dev/>Go</a> backend</li><li><a href=https://aws.amazon.com/>AWS</a> for infrastructure<ul><li><em>EDIT: This was correct but oh boy, in the worst way</em></li></ul></li></ul><p>The CTO and I were talking about <a href=https://encore.dev/>encore.dev</a> leading up the interview so I built on <a href=https://encore.dev/docs/tutorials/slack-bot>their chatbot
example</a> to
make <a href=https://github.com/initialed85/slack-openai>a ChatGPT variant</a> to get some hands-on experience with the
framework.</p><p>It wasn&rsquo;t bad, I might do a post about it later on; but basically from the discussion with the CTO I infer that they&rsquo;re
either using Encore or they&rsquo;re doing serverless AWS without a framework and finding that a challenge.</p><p>So I guess they&rsquo;re either using Encore or they&rsquo;re at least using Go (I assume serverless) and the CTO is trying to
figure out how to reduce toil- fortunately Go is a language I&rsquo;m very comfortable with so I think I can help out there.</p><p><em>EDIT: Sure not serverless</em></p><p>Without truly knowing the spectrum of challenges they&rsquo;re facing, I&rsquo;m planning to bring some of my experience with around
a robust software development lifecycle to the table and drive adoption from the front (by doing):</p><ul><li>Keep the whole team abreast of the context around what we&rsquo;re focused on right now<ul><li><em>I think we&rsquo;ve managed to achieve this</em></li></ul></li><li>Keep tickets small with clean acceptance criteria (and functional test cases if possible)</li><li>Make good use of a code repo<ul><li>Monorepo can be a nice way to avoid dependency hell<ul><li><em>EDIT: We got to this, but I didn&rsquo;t do it alone; much thanks to a guy called Luke Gelmi who came in keen and
excited and drove this to victory</em></li></ul></li></ul></li><li>Have an effective pull request process<ul><li>Aim for small / focused PRs</li><li>Aim for a quick turnaround on PRs</li><li>Try to balance feedback between &ldquo;objectively bad&rdquo; vs &ldquo;just not my style&rdquo; (don&rsquo;t squash creativity)</li><li><em>EDIT: I think we managed to hit all these</em></li></ul></li><li>Make it easy to spin up prod-like environments for development and testing<ul><li><em>EDIT: Definitely did this and I think it was our biggest gain</em></li></ul></li><li>Make it easy to execute a suite of tests against a prod-like environment<ul><li><em>EDIT: More or less achieved this</em></li></ul></li><li>Have a suite of tests and execute them at sensible times<ul><li>When we commit changes to a PR</li><li>When we merge a PR</li><li>Every night (because external dependencies sometimes break!)</li><li><em>EDIT: Got all this with compromises; orchestrating a test environment was hard, so unit / integration tests run
on commit, end-to-end tests are run locally (manually) and nightly against the deployed dev / staging
environments</em></li></ul></li><li>Store artifacts against commit hashes<ul><li>We might have to roll back and maybe that version doesn&rsquo;t build any more (but we know it works)</li><li><em>EDIT: We did this</em></li></ul></li><li>Store all prod-related configuration in a code repo<ul><li><em>EDIT: We did this too</em></li></ul></li><li>Drive prod-related deployments from that code repo<ul><li><em>EDIT: Yep</em></li></ul></li><li>Have the right observability for what we&rsquo;re doing<ul><li>Are we busy enough to rely on metrics?</li><li>Is our logging good enough to drill into problem areas?</li><li>Are our individual transactions important enough that we need to care about tracing?</li><li><em>EDIT: Well we&rsquo;ve got Grafana and we&rsquo;ve got some metrics but it didn&rsquo;t go much deeper than that- structured
logging / tracing is still a TODO (but this represents sensible prioritisation)</em></li></ul></li></ul><p>All of the above is underpinned by some good rules of thumb:</p><ul><li>Dependencies should be version-pinned<ul><li>There will be enough problems simply with external package repo availability</li><li><em>EDIT: This was pretty much already in-hand thanks to <code>package.json</code> and <code>go.mod</code></em></li></ul></li><li>Important dependencies should be vendored<ul><li>Remember when everyone started yanking their Python 2 packages from PyPI?</li><li>Remember when Debian deprecated the Slim <code>dpkg</code> repo?</li><li><em>EDIT: This was prior experience that hasn&rsquo;t been relevant as it turned out</em></li></ul></li><li>Artifact we deploy should be stored and versioned<ul><li>Makes it easy to redeploy it elsewhere, pick it apart for forensics etc</li><li><em>EDIT: This was valuable and we did it</em></li></ul></li><li>Deployments should be immutable<ul><li>If we need to roll back, we should be able to do so by deploying a previous version</li><li><em>EDIT: Same</em></li></ul></li><li>Deployments should be automated or close to automated<ul><li>It should be easy to execute a deployment, ideally easy enough that something else does it on our behalf</li><li><em>EDIT: This has been hugely valuable</em></li></ul></li><li>Post-mortems we do should be truly blameless<ul><li>Individuals haven&rsquo;t failed, our processes have</li><li><em>EDIT: We haven&rsquo;t been rigid at post-mortems; I&rsquo;ve driven blameless as hard as I can, we&rsquo;re just not very
structured in post-mortems</em></li></ul></li></ul><p>Automation helps a great deal with this:</p><ul><li>Automated testing of components when their code changes<ul><li>e.g. unit tests / integration tests</li><li><em>EDIT: Our coverage is definitely better here</em></li></ul></li><li>Automated storing of component artifacts when their tests pass<ul><li>e.g. Docker images / binaries</li><li><em>EDIT: Well, we don&rsquo;t push binaries if the preceding tests don&rsquo;t pass</em></li></ul></li><li>Automated deployment of environments based on the state of a configuration management repo<ul><li>e.g. CDK / Terraform</li><li><em>EDIT: Yep, thx <a href=https://argo-cd.readthedocs.io/en/stable/>Argo</a></em></li></ul></li><li>Automated testing of an environment when it&rsquo;s deployed<ul><li>e.g. end-to-end tests / system tests</li><li><em>EDIT: Well, sort of- we&rsquo;ve got the nightlies</em></li></ul></li></ul><p>This all sounds very imperative and prescriptive but I&rsquo;m a pragmatic guy and we&rsquo;ll apply these things in a way that
works for us- ultimately we&rsquo;re trying to reduce toil and increase velocity but along the way there&rsquo;ll for sure be some
critical items that need muscling a certain way to meet milestones and naturally those items will be prioritised above
all else.</p><p>I guess let&rsquo;s say the above is a strategy but ultimately the needs of the business will dictate the tactics.</p><h3 id=excitement-or-anxiety>Excitement or anxiety?<a hidden class=anchor aria-hidden=true href=#excitement-or-anxiety>#</a></h3><p>I&rsquo;m pretty comfortable with the soft-skills side of team leadership and I back myself technically, but I&rsquo;m not strong
with cloud so I wanted to try to get a feel for things before going in.</p><p><em>EDIT: Predictably, more challenges than I had catered for, but I guess I had sort of catered for there being more
challenges than I had catered for so it worked out okay</em></p><p>Probably to a point of fault, I don&rsquo;t like to plan and theorise too much before I start experimenting so I decided to
slap together <a href=https://github.com/initialed85/github-cdk-testing>a demo repo to test out some concepts</a>.</p><p><em>EDIT: This spike was largely a waste of time, we landed with <a href=https://www.pulumi.com/>Pulumi</a>
and <a href=https://argo-cd.readthedocs.io/en/stable/>Argo</a></em></p><p>It&rsquo;s not complete yet, I wanna try to cover off on the common serverless concepts but so far I&rsquo;ve really only got the
following:</p><ul><li>A minimal Go backend that so far just responds with some context about the request</li><li>A minimal <a href=https://react.dev/>React</a> frontend that is presently nothing
beyond <a href=https://create-react-app.dev/>Create React App</a></li><li>Some CDK to deploy the above with the following concepts:<ul><li>Lambda for the backend</li><li>S3 for the frontend</li><li>ALB in front of the Lambda</li><li>CloudFront in front of it all</li><li>A resource group to track it all</li></ul></li></ul><p>I&rsquo;ve tried to take my own medicine re: strategy above with a GitHub Action that does the following:</p><ul><li>Test all components as a gating mechanism</li><li>Build all the component artifacts</li><li>Ensure a &ldquo;dependencies&rdquo; infrastructure stack is deployed<ul><li>Basically just an S3 bucket for artifacts</li></ul></li><li>Deploy the component artifacts to the artifacts bucket</li><li>Deploy the intended environment (e.g. dev, staging, prod) infrastructure stack<ul><li>Referring to the artifacts in the artifacts bucket</li></ul></li></ul><p>Right now the building of the artifacts and the deploying of the artifacts are artificially coupled because there is no
configuration management repo to drive the deployment of the infrastructure stack; decoupling them should be easy though
because the artifacts are &ldquo;versioned&rdquo; in the artifacts bucket so it would be trivial to tell the infrastructure stack
which version to use.</p><h2 id=the-reality-between-may-and-december-ish>The reality between May and December-ish<a hidden class=anchor aria-hidden=true href=#the-reality-between-may-and-december-ish>#</a></h2><p>So, we&rsquo;re back in realtime now- I&rsquo;m not sure where to start; I guess lets go through some categorised dot-points&mldr;</p><p><img loading=lazy src=/posts/cloudy-with-a-chance-of-vendor-lock-in-balls/image-2.png alt=image-2.png></p><h3 id=clint-eastwood>Clint Eastwood<a hidden class=anchor aria-hidden=true href=#clint-eastwood>#</a></h3><ul><li>The team was excited and keen for some leadership</li><li>The app + platform was (just) launched and mostly working (especially given the fairly complicated task it had)</li><li>There were 3 cloud environments (dev, staging, prod)</li><li>Commits to the master branch of each repo would cause (except for the mobile app) the build and deployment of the
component in question</li></ul><h3 id=lee-van-cleef>Lee Van Cleef<a hidden class=anchor aria-hidden=true href=#lee-van-cleef>#</a></h3><ul><li>Each dev&rsquo;s local environment / local database was entirely self-managed<ul><li>So the completeness / correctness of your environment depends essentially on how skilled you are and how helpful
the dev next to you is</li></ul></li><li>Everyone was developing on Windows</li><li>No unit tests and no end-to-end tests (maybe one or two narrow-ish integration tests, but, to be fair, for some
complicated parts of the system)</li><li>A bunch of the senior devs (responsible for laying all the foundations) had got burnt out and left<ul><li>Two of them remained with about 2 / 3 weeks left when I arrived</li></ul></li><li>The breadth of the features of the system was (is) way too big for the problem domain<ul><li>As a result the system was large for how young it was, but nothing worked properly (due to the small team
sprinting to
kick something out the door but being swamped with too much functionality for an MVP)</li></ul></li></ul><h3 id=eli-wallach>Eli Wallach<a hidden class=anchor aria-hidden=true href=#eli-wallach>#</a></h3><ul><li>Levels of abstraction were low (and levels of repetition were high)<ul><li>I don&rsquo;t know for sure, but I think this is a byproduct of folks not having confidence in their code changes (no
tests) and <em>probably</em> a decent amount of ChatGPT</li></ul></li><li>It doesn&rsquo;t seem that the architecture side of the software was thought about a lot and it doesn&rsquo;t look like code
quality was pushed much in code reviews<ul><li>External interfaces would be a mixture of <code>CamelCase</code> and <code>snake_case</code> with no real pattern</li><li>Pointers would be used far too much (when not required) causing numerous nil pointer panics where they could have
been entirely avoided</li><li>The flow of data through the system / the way it affected the state of the model was all over the shop<ul><li>Some poll-based, some event-based, no thought given to concurrency problems / locking</li></ul></li></ul></li><li>The &ldquo;DevOps&rdquo; capability was a part-time resource in another country, on a different timezone<ul><li>Very little work-in at all with the dev team (some of them didn&rsquo;t know he existed); basically the opposite of
DevOps!</li></ul></li><li>The 3 cloud environments were similar but not the same on account of being built entirely by hand<ul><li>Absolutely no <a href=https://en.wikipedia.org/wiki/Infrastructure_as_code>IaC</a> to speak of</li><li>Absolutely no backups of all the hand-crafted snowflake resources</li></ul></li><li>The deployment mechanism for the backend was worrying- a Bitbucket pipeline would use the default image (gasp) to
build a Go binary for an unknown glibc version and literally SSH it through the front door of the backend EC2 VM where
it was run entirely natively<ul><li>There&rsquo;s a lot to unpack here<ul><li>The glibc thing bit us when Bitbucket arbitarily updated (as you&rsquo;d expect) the Go version bundled in their CI
image (resulting in a Go binary that wasn&rsquo;t compatible with the glibc available on the EC2 VM)</li><li>The EC2 VM had to be open to the world to permit Bitbucket to SSH artifacts in</li><li>There was no rollback mechanism; the proven, running artifact was ripped out of existence and thrown in the
bin then the new one was started- if the new one didn&rsquo;t work, you&rsquo;d have to start typing <em>real fast</em></li></ul></li></ul></li><li>The deployment mechanism for the frontend was even more worrying- a Bitbucket pipeline would literally SSH the code
over to the frontend EC2 VM and then build it all there (somebody had already manually installed all the dependencies)</li><li>We had dared to completely hand-roll Certbot stuff to handle LetsEnrypt cert changeovers<ul><li>Cron and slapped-together Bash- an accident just waiting to happen (and this is coming from a big fan of Bash)</li></ul></li></ul><h3 id=the-approach-since-then>The approach since then<a hidden class=anchor aria-hidden=true href=#the-approach-since-then>#</a></h3><p>I was immediately thrown into deep water (fair I guess, I had come on as the lead dev) and whether to sound me out or
whether through necessity, the CTO had me wading through logs to get to the bottom of some prod issue within 2 days of
getting there.</p><p>Fortunately Ops is my middle name and I&rsquo;m familiar with AWS so finding the logs and the subsequent problem wasn&rsquo;t too
hard- it ended up being a silly and obvious nil pointer panic (one of the numerous that would plague us for a few
months until we installed a handle-level panic recovery mechanism).</p><h4 id=repeatability>Repeatability<a hidden class=anchor aria-hidden=true href=#repeatability>#</a></h4><p>I was paralyzed for a week or two to be honest, just absolutely swamped in the sheer number of problems- when everything
seems to be in a critical state, it becomes hard to work out where the right place to start chewing is.</p><p>We worked for a bit to get things halfway stable and get some grasp on what the team had promised to do in the near term
and build a plan for doing that and then the obvious path started emerging.</p><p>We needed repeatable environments; these would stop us falling over ourselves, spending 2 days down the rabbithole
chasing bugs that turned out to be stray stale data in local snowflake databases etc.</p><p>This was no mean feat and frankly it took months, but we had something workable fairly early; here&rsquo;s where it landed:</p><ul><li>Get everyone off of Windows and onto Linux<ul><li>We had started off getting the devs out of native Windows dev and into WSL2 but it almost introduced more problems
than it solved</li><li>Moving to Ubuntu (batteries included) was well received and we saw a lot of benefit simply by writing code on the
same platform we shipped code</li></ul></li><li><a href=https://devenv.sh/>Devenv</a> to handle the native dependencies (Go, Node, Android emulator, all sorts) and reduce the
effort required to spin up a new dev (and reduce the odd issues introduced because e.g. Joe Bloggs has Node 16 and
Jane Bloggs has Node 18)</li><li><a href=https://docs.docker.com/compose/>Docker Compose</a> to orchestrate dependencies like Postgres, Stripe Webhook Forwarder
etc as well as the actual services<ul><li>We weren&rsquo;t yet running containers in prod, but I had a pretty good idea that this was where we were headed so
getting containers in dev was a good way to get everyone exposed</li></ul></li><li><a href=https://github.com/DarthSim/overmind>Overmind</a> to orchestrate native dependencies<ul><li>This was a necessity to help devs move fast with full-stack changes (enabling hot reloads etc)</li><li>It did introduce a lot of complexity however (because full hot reloading meant running natively which means we
lost the containerisation benefits)</li></ul></li></ul><p>So we ended up with a thing we call &ldquo;the dev-env&rdquo; (which is actually a name stolen from my last workplace and I daresay
they weren&rsquo;t the first place to describe such a concept) and two modes to operate it in (fully containerised or
partially containerised with services running natively with hot reloading).</p><p>It&rsquo;s been a big win- a developer comes in, spins up their dev-env which restores and migrates fresh databases, creates
some fresh users (automated, but in the same way a user would signup, so free testing there), provisions some of the
domain concepts that the system operates around and leaves them with some instructions on how to open the various
services in their browser / emulator / mobile phone.</p><h4 id=automated-testing>Automated testing<a hidden class=anchor aria-hidden=true href=#automated-testing>#</a></h4><p>Now that we had repeatable environments, the next thing we needed was some level of confidence that the system worked as
expected- we had behaviour spread between the mobile app, the NextJS web app and the Go backend so I opted for Python as
an easy way to pull together some end-to-end tests.</p><p>I started out with a naive approach of just trying to cover every endpoint but some of the valuable interactions were
spread across multiple endpoints and more than once service.</p><p>So, having already built out Python clients for every service (including Stripe) I basically built out some test cases
that covered the most valuable user interactions and extended to a few common edge cases near them.</p><p>Just doing this exercise found heaps of stuff (and heaps of inconsistencies, essentially race conditions) and now the
same tests (which have grown a lot) are a valuable part of any release (and the nightly test runs).</p><p>Unfortunately, I still haven&rsquo;t been able to get entirely automated (e.g. on-commit) tests running in terms of entirely
spinning up a clean and isolated dev-env and then executing tests against it mainly for the following reasons:</p><ul><li>The full dev-env is heavy</li><li>Bitbucket is super constrained in the subset of Docker capability it gives you</li></ul><p>So, a full clean end-to-end test run needs to be run on a dev&rsquo;s workstation and the nightly runs happen against the
already-deployed environments.</p><p>Maybe I&rsquo;ll spin up Jenkins or TeamCity or something like that, but its basically got to the point where we&rsquo;re getting
90% of the value and that last 10% will take (has taken already) too much time for not that much value.</p><h4 id=better-deployments>Better deployments<a hidden class=anchor aria-hidden=true href=#better-deployments>#</a></h4><p>It&rsquo;s no secret that I love Kubernetes but I promise I&rsquo;m not just a fanboi, truly I think it is great software- having
wrangled as much Ops stuff as I have and been one of the key players in building out bespoke deployment tooling, you can
see that the folks who built Kubernetes happened upon the same journey we did and came up with answers for all of it.</p><p>Things like being able to describe the desired state of your system as code, being able to diff the current vs desired
state and have the system achieve it for you, automating the toil around rolling out new versions of services, rolling
back on failure, doing something useful with Docker healthchecks (startup / liveness probes etc)- I really do think it
represents the peak of generic tech for shipping things as containers.</p><p>So naturally, that&rsquo;s where we went- I got everything bundled into containers, I got it all building and pushing to AWS
ECR on commit and I deployed an AWS EKS cluster (using Pulumi for the base IaC and Argo for the &ldquo;app&rdquo; IaC) to ship it
all on.</p><p>And I have to say, it has not missed a single beat and we simply do not worry about deployments any more; but here&rsquo;s the
best (and if you subscribe to the anti-hype, unexpected) part:</p><p>It&rsquo;s cheaper to run.</p><p>Well, cheaper to run than what we had before- we used to have about 12 (small to medium) EC2 VMs spanning the 3
environments and assorted services and understandably because hand-wrangling Nginx is difficult if you wanna stack all
your services on a single VM.</p><p>Now we&rsquo;ve got 5 (smaller) nodes (probably only need 4) for all 3 environments and a stack of ancillary services as well
as monitoring and I don&rsquo;t need to worry about patching or anything.</p><p>So since I started, we&rsquo;ve grown our service footprint a reasonable amount but somehow halved our monthly cloud spend
and saved who knows how much developer time in putting fixes on top of fixes for bespoke deployment tooling (and dealing
with the outages that come with that).</p><h4 id=monorepo>Monorepo<a hidden class=anchor aria-hidden=true href=#monorepo>#</a></h4><p>One of the first things I did when I started this new gig was set up about setting up a monorepo- but frankly I didn&rsquo;t
get very far, I got too caught up with trying to maintain throughput on features and releases while trying to improve
our Way of Working.</p><p>3 months in, all I really had to show for in the monorepo was the dev-env, the end-to-end tests and some of the
ancillary services that we grew after I started.</p><p>Luckily for me, we happened to hire an absolutely jet frontend dev a couple of months ago and he too believed in the
value of a monorepo but unlike me, he wasn&rsquo;t bogged down keeping the team ticking and keeping the lights on, so with
very little guidance he was able to keep building out the rest of the monorepo to help us realise the dream.</p><p>He put in the hard yards getting the frontend code moved over and getting the dev-env working from the entirely new
paths, leaving me with a bit of work to do in terms of getting all the Docker images building again and wiring in all
the deployment pipelines and it was all done and dusted in about a month.</p><p>The win has been huge, devs have gone from opening 3 PRs for a single piece of work down to just 1 PR, any breaking
changes can be looked at entirely in the context of the other changes for the same release, devs aren&rsquo;t losing hours
only to find the issue is because they were working on the frontend and had forgot to pull the latest backend etc.</p><h4 id=interesting-findings>Interesting findings<a hidden class=anchor aria-hidden=true href=#interesting-findings>#</a></h4><ul><li>I can operate for about 2 weeks going to bed at 3am before my body takes over and demands sleep<ul><li>No guarantees about what sort of a person I am to be around as I near the 2 week mark</li></ul></li><li>I can migrate a prod environment from EC2 to Kubernetes in the quiet period between the service going quiet-ish (
midnight) and before business picks up again (5am-ish) with minimal downtime (mostly just the no-mans land while DNS
is
in an uncertain state)</li><li>I don&rsquo;t need anywhere near as much test coverage as I thought I did (coming from a large Python codebase)- I think
this is because of the strongly-typed nature of Go<ul><li>Once this dawned on me, I became a lot less stressed, because I realised we weren&rsquo;t in quite the bad shape I
thought we were</li><li>End-to-end test coverage is still important though, because complex behavioural / business domain-level bugs
aren&rsquo;t notably affected by things like strong typing in my experience</li></ul></li><li>I need to keep re-learning patterns about myself<ul><li>I&rsquo;ll start out with a bit of &ldquo;let&rsquo;s just hack this thing in&rdquo; mindset and it always, always grows into &ldquo;okay this
is more complex than I thought, time to write some tests&rdquo; (I should really just start with the tests)</li></ul></li><li>The initially very daunting feeling of a large and foreign codebase and my natural inclination to hack and slash
continue to take a while to equalize<ul><li>It&rsquo;s really hard to tell (without somebody to ask) what parts of the code are important vs not important, proven
and reliable vs flaky etc but until you know, you&rsquo;ve really gotta treat lightly<ul><li>I&rsquo;m always saying this, but I still, STILL don&rsquo;t live it enough</li></ul></li></ul></li></ul><h4 id=other-items-of-note>Other items of note<a hidden class=anchor aria-hidden=true href=#other-items-of-note>#</a></h4><p>We&rsquo;re building out a new service that I can&rsquo;t really speak a lot about at present, but it&rsquo;s gonna allow us to cut out a
bunch in current software licensing and it&rsquo;s been super exciting to work on.</p><p>I&rsquo;ve been working closely with a somewhat junior Go dev that started the same day I did and it&rsquo;s been really great to
see him grow as a pragmatic Go developer by working on this new service (that doesn&rsquo;t fit the typical mould of "
web-based backend" and is more about complex interactions with devices deployed in the field).</p><p>I&rsquo;ve been able to share some wisdom and guide the approach (and I&rsquo;ve had to compromise on some items- I swear buddy
we&rsquo;re gonna need that FSM and the complexity will be worth it but hey, you win for now) and I&rsquo;m proud of the shape its
taken.</p><h4 id=in-closing>In closing<a hidden class=anchor aria-hidden=true href=#in-closing>#</a></h4><p>I&rsquo;ll probably park the article here, it&rsquo;s taken 6 months to write and its an almighty wall of text. All in all, I&rsquo;m
enjoying the new job and while it&rsquo;s definitely a paycut (being a startup), the open / unsolved nature of the problem
space and the (initially overwhelming) amount of opportunity to deliver some value has been super rewarding.</p></div><footer class=post-footer><ul class=post-tags></ul></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//initialed85.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2023 <a href=https://initialed85.cc/>initialed85's misc tech stuff</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>